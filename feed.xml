<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiawei&#39;s homepage</title>
    <description>Jiawei&#39;s homepage
</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 19 Aug 2017 20:03:27 +0800</pubDate>
    <lastBuildDate>Sat, 19 Aug 2017 20:03:27 +0800</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Node, React, Passport</title>
        <description>&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tinkerstash/node-react-passport&quot;&gt;Our Github page&lt;/a&gt; with React frontend, Node backend.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;We want to build a basic example that demonstrate the use of the following technologies:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;React for frontend.&lt;/li&gt;
  &lt;li&gt;Node-Express for backend.&lt;/li&gt;
  &lt;li&gt;Axios for ajax (instead of jquery).&lt;/li&gt;
  &lt;li&gt;Passport-local for authentication.&lt;/li&gt;
  &lt;li&gt;Postgres (instead of Mongo) for potential big joins.&lt;/li&gt;
  &lt;li&gt;Tape, Supertest for backend unit tests.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On top of that, we use some smaller convenient libraries. For frontend, we use:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;React-Toastr for convenient display of messages.&lt;/li&gt;
  &lt;li&gt;Bootstrap for simple styling.&lt;/li&gt;
  &lt;li&gt;React-confirm-alert for confirm dialog in React.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For backend, we use:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Underscore for lots of nice utilities.&lt;/li&gt;
  &lt;li&gt;Crypto for hashing salt + password.&lt;/li&gt;
  &lt;li&gt;Continuation-local-storage for passing req, rsp globally.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 05 Aug 2017 00:00:00 +0800</pubDate>
        <link>/projects/2017/08/05/node_react_passport.html</link>
        <guid isPermaLink="true">/projects/2017/08/05/node_react_passport.html</guid>
        
        
        <category>projects</category>
        
      </item>
    
      <item>
        <title>Matrix Pencil Sparse Fourier Transform</title>
        <description>&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tinkerstash/mpsft/blob/master/report/report.pdf&quot;&gt;&lt;strong&gt;Brief report&lt;/strong&gt;&lt;/a&gt; describes how MPSFT works.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dspace.mit.edu/handle/1721.1/83691?show=full&quot;&gt;PhD thesis&lt;/a&gt; contains some theory.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tinkerstash/mpsft&quot;&gt;Github page&lt;/a&gt; has the implementation details.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;SFT (sparse Fourier transform) algorithms aim to perform discrete Fourier transform in O(S) time, ignoring log factors, where S is the sparsity in frequency domain. In other words, the solution has a support of size S, plus some noise.&lt;/p&gt;

&lt;p&gt;In MPSFT (Matrix Pencil Sparse Fourier Transform), we apply the matrix pencil method to improve the accuracy of mode identification and to reduce the chance of creating spurious modes (and having to correct them later). It makes SFT algorithms more feasible and practical. For N=2^22, we are faster than FFTW when S is less than around 1800. AAFFT is faster for a smaller range of S, say around &amp;lt;= 200. A more recent work &lt;a href=&quot;http://users.math.msu.edu/users/markiwen/Papers/DiscreteSFT.pdf&quot;&gt;DMSFT&lt;/a&gt; seems to be somewhat competitive with MPSFT.&lt;/p&gt;

&lt;h1 id=&quot;results&quot;&gt;Results&lt;/h1&gt;

&lt;p&gt;In the plot below, we fix N=2^22 and vary S (sparsity) and plot the running time. SFFT1 and SFFT2 are faster but they have a runtime of O(sqrt(NS)) ignoring log factors.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tinkerstash/mpsft/master/report/graph/runtime_vary_k.png&quot; alt=&quot;plot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the plot below, we fix K=50 and increase N. Here we see that MPSFT will be faster than SFFT1, SFFT2 for N being around 2^24.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tinkerstash/mpsft/master/report/graph/runtime_vary_n.png&quot; alt=&quot;plot&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;basic-ingredients&quot;&gt;Basic ingredients&lt;/h1&gt;

&lt;p&gt;We bin the signal in frequency domain by convolving with a &lt;strong&gt;smoothed boxcar filter&lt;/strong&gt;. This can be achieved in time domain by multiplying with the corresponding window.&lt;/p&gt;

&lt;p&gt;In each bin, we hope there is only one mode. Then using the &lt;strong&gt;matrix pencil method&lt;/strong&gt;, we can identify each bit of the mode frequency and also detect if there is indeed exactly one mode.&lt;/p&gt;

&lt;p&gt;We exploit some &lt;strong&gt;symmetry&lt;/strong&gt; to roughly halve the computation cost of the matrix pencil method. We apply &lt;strong&gt;SIMD&lt;/strong&gt; optimization to achieve &amp;gt;=2X speedup.&lt;/p&gt;
</description>
        <pubDate>Sat, 05 Aug 2017 00:00:00 +0800</pubDate>
        <link>/projects/2017/08/05/mpsft.html</link>
        <guid isPermaLink="true">/projects/2017/08/05/mpsft.html</guid>
        
        
        <category>projects</category>
        
      </item>
    
      <item>
        <title>GPU SoftImpute</title>
        <description>&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tinkerstash/gpuimpute&quot;&gt;Our Github page&lt;/a&gt; with GPU-accelerated version of SoftImpute.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.05487&quot;&gt;Accelerated proximal gradient for SoftImpute&lt;/a&gt; paper by Quanming Yao, James T. Kwok.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/quanmingyao/AIS-impute&quot;&gt;Matlab implementation&lt;/a&gt; by the same folks.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/mazumder10a.pdf&quot;&gt;Original SoftImpute paper&lt;/a&gt; by Mazumder, Hastie, Tibshirani.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;We are interested in GPU-accelerating the SoftImpute algorithm from Hastie et al’s paper. This is a SVD-based collaborative filtering algorithm.&lt;/p&gt;

&lt;p&gt;We use randomized SVD as it seems to work better with GPUs. We use the accelerated proximal gradient method also mentioned in Quanming Yao et al’s paper. See below for references.&lt;/p&gt;

&lt;p&gt;We compare these GPU-accelerated versions against the CPU version. We see that there is at least a &lt;em&gt;10X&lt;/em&gt; speedup. We also compare against a simple SGD implementation with a bit of tuning. All CPU implmentations, SoftImpute or SGD, use Eigen or BLAS. They are pretty efficient, to be fair.&lt;/p&gt;

&lt;p&gt;For the data, currently we only have the MovieLens 20M dataset. We split the data into 5 parts and use one part for measuring the error. (There is no validation set but we hardly do any tuning anyway.)&lt;/p&gt;

&lt;p&gt;The results seem to be that SGD is still faster, even when on single core.&lt;/p&gt;

&lt;p&gt;Our CPU is a I7-6700K. Our GPU is a Titan-X with 12G RAM.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/tinkerstash/gpuimpute/blob/master/results/plot1.png?raw=true&quot; alt=&quot;plot&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The slowest is CPU-NoAcc which is the CPU version with un-accelerated proximal gradient.&lt;/li&gt;
  &lt;li&gt;The next slowest is CPU-Acc which is the CPU version with accelerated proximal gradient.&lt;/li&gt;
  &lt;li&gt;The GPU versions are all significantly faster, seemingly &amp;gt;10X. (We do have a fast GPU unfortunately.)&lt;/li&gt;
  &lt;li&gt;However, SGD still seems to be the fastest.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The most tricky part of the GPU code is probably the evaluation of many short inner products. It seems to be the bottleneck, and we have to write a custom kernel to do that efficiently.&lt;/p&gt;
</description>
        <pubDate>Sat, 05 Aug 2017 00:00:00 +0800</pubDate>
        <link>/projects/2017/08/05/gpuimpute.html</link>
        <guid isPermaLink="true">/projects/2017/08/05/gpuimpute.html</guid>
        
        
        <category>projects</category>
        
      </item>
    
  </channel>
</rss>
